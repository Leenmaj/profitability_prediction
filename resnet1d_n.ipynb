{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4470a145-cc3e-45ab-8b8b-9416e9d73f96",
   "metadata": {
    "id": "4470a145-cc3e-45ab-8b8b-9416e9d73f96",
    "outputId": "350cef80-c8ce-4005-c144-671fcbd8f3fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WLCZqhhZcp0g",
   "metadata": {
    "id": "WLCZqhhZcp0g"
   },
   "source": [
    "# Checking if GPU is in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7177e503-d0b2-4c7e-8b81-42a1b25370da",
   "metadata": {
    "id": "7177e503-d0b2-4c7e-8b81-42a1b25370da",
    "outputId": "4e926011-479b-43ef-8cba-25542d112b8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflow\n",
      "Version: 2.12.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages\n",
      "Requires: tensorflow-intel\n",
      "Required-by: \n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip show tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e464140a-a368-4bfb-9955-d6cf6645fd9c",
   "metadata": {
    "id": "e464140a-a368-4bfb-9955-d6cf6645fd9c",
    "outputId": "a4148050-62f5-461c-cac2-ab9f19e29604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.12.0\n",
      "GPU Devices: []\n",
      "Local Devices: [name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 15634773640242461994\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"GPU Devices:\", tf.config.list_physical_devices('GPU'))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(\"Local Devices:\", device_lib.list_local_devices())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbf1d787-2f46-439d-8614-823b6795f980",
   "metadata": {
    "id": "cbf1d787-2f46-439d-8614-823b6795f980",
    "outputId": "3f3ecb27-d9fe-45eb-fa12-5c9452adee9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11dd903e-88e2-4028-a1d6-e529f80188ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch Version: 2.5.1+cu121\n",
      "CUDA Available: True\n",
      "CUDA Version: 12.1\n",
      "cuDNN Version: 90100\n",
      "Number of GPUs: 1\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(\"PyTorch Version:\", torch.__version__)\n",
    "print(\"CUDA Available:\", torch.cuda.is_available())\n",
    "print(\"CUDA Version:\", torch.version.cuda)\n",
    "print(\"cuDNN Version:\", torch.backends.cudnn.version())\n",
    "print(\"Number of GPUs:\", torch.cuda.device_count())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e7cfcc2a-2ec7-4152-a3cd-598c10f62230",
   "metadata": {
    "id": "e7cfcc2a-2ec7-4152-a3cd-598c10f62230",
    "outputId": "b9ba6cd3-fd3b-4173-a127-a83a2c912bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cc272962-540f-4ae4-9a1b-aefca92133cb",
   "metadata": {
    "id": "cc272962-540f-4ae4-9a1b-aefca92133cb",
    "outputId": "ef4ab500-73e4-42bd-9803-5a819251a8fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1660 Ti with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac0d9e6e-a97b-458d-a8e1-d7630dfa37ed",
   "metadata": {
    "id": "ac0d9e6e-a97b-458d-a8e1-d7630dfa37ed",
    "outputId": "f569af0c-2b66-42ca-dd05-5cbd8c95ec95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\l_alm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2788cf5b-fb41-4dd7-8b3c-ba8e8d6a247f",
   "metadata": {
    "id": "2788cf5b-fb41-4dd7-8b3c-ba8e8d6a247f",
    "outputId": "863e4c7e-347d-473d-afa0-96dee1c861f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.anaconda', '.bash_history', '.cache', '.conda', '.condarc', '.config', '.continuum', '.dropbox_bi', '.gitconfig', '.grasp_settings', '.idlerc', '.ipynb_checkpoints', '.ipython', '.jupyter', '.keras', '.lesshst', '.m2', '.matplotlib', '.ms-ad', '.nbi', '.packettracer', '.spyder-py3', '.ssh', '.vscode', '1D-ResNet-SE-LSTM-main', '3D Objects', 'ansel', 'AppData', 'Apple', 'Application Data', 'attempt2.ipynb', 'book.jpg', 'bus.jpg', 'chat_finetune_ConversationRedditData_Llama_2_7Bchat.ipynb', 'cifar 10 classification.ipynb', 'Cisco Packet Tracer 8.2.2', 'Contacts', 'Cookies', 'CSC 340', 'cudnn-windows-x86_64-8.6.0.163_cuda11-archive', 'customerTargeting.csv', 'data', 'Documents', 'Downloads', 'Dropbox', 'ds-phase2', 'euclidean_distance.c', 'Favorites', 'fmri.mat', 'frames_output', 'gcc', 'Homework_1.ipynb', 'IntelGraphicsProfiles', 'Jedi', 'jjjj', 'leen', 'Links', 'Local Settings', 'mingw-get-setup.exe', 'miniconda3', 'mkscancer-master', 'Music', 'My Documents', 'myenv', 'NetHood', 'NTUSER.DAT', 'ntuser.dat.LOG1', 'ntuser.dat.LOG2', 'NTUSER.DAT{2ad838bc-efea-11ee-a54d-000d3a94eaa1}.TM.blf', 'NTUSER.DAT{2ad838bc-efea-11ee-a54d-000d3a94eaa1}.TMContainer00000000000000000001.regtrans-ms', 'NTUSER.DAT{2ad838bc-efea-11ee-a54d-000d3a94eaa1}.TMContainer00000000000000000002.regtrans-ms', 'ntuser.ini', 'OneDrive', 'OneDrive - King Suad University', 'output.png', 'preprocessing.py', 'PrintHood', 'Recent', 'resnet1d-master', 'ResNet1D-VariableLengthPooling-For-TimeSeries-master', 'resnet1d.ipynb', 'resnet1d_n.ipynb', 'runs', 'Saved Games', 'Searches', 'SendTo', 'source', 'Start Menu', 'Templates', 'tf_gpu_env', 'tut web', 'Untitled.ipynb', 'untitled.py', 'Untitled1.ipynb', 'Untitled10.ipynb', 'Untitled11.ipynb', 'Untitled12.ipynb', 'Untitled2.ipynb', 'Untitled3.ipynb', 'Untitled4.ipynb', 'Untitled5.ipynb', 'Untitled6.ipynb', 'Untitled7.ipynb', 'Untitled8.ipynb', 'Videos', 'WLASL-master', 'wlasl.ipynb', 'WLASL100_Instances.csv', 'YOLO-v8-Object-Detection-main', 'YOLOV8.ipynb', 'yolov8n.pt', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(os.listdir())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34f185a8-46be-45b3-9949-d1c2a616a94b",
   "metadata": {
    "id": "34f185a8-46be-45b3-9949-d1c2a616a94b",
    "outputId": "7246d400-9052-47ef-e969-5064297e18c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "84ca187e-d3a5-4250-88c5-469e662bff78",
   "metadata": {
    "id": "84ca187e-d3a5-4250-88c5-469e662bff78",
    "outputId": "bd13fd30-702b-4cbc-9589-830cb0bc1cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (3.9.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (10.3.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b904ee8f-194e-4c38-9ed7-649e5539ec34",
   "metadata": {
    "id": "b904ee8f-194e-4c38-9ed7-649e5539ec34",
    "outputId": "3b9f1f4c-3e9c-41e9-f879-e95c264d8585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8fd18bf0-7f33-44b5-90c1-c113ae337652",
   "metadata": {
    "id": "8fd18bf0-7f33-44b5-90c1-c113ae337652",
    "outputId": "a66edff5-49b6-48c4-86aa-e750f3a2251c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboardX in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboardX) (1.23.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboardX) (24.2)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboardX) (4.25.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8dca0602-f1e6-4e3f-ae56-033e4f882728",
   "metadata": {
    "id": "8dca0602-f1e6-4e3f-ae56-033e4f882728",
    "outputId": "5d18c88f-3b3d-4eb4-f9ac-e2b9b5f54670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QRhG6K3SdAYv",
   "metadata": {
    "id": "QRhG6K3SdAYv"
   },
   "source": [
    "# Adjusting to directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5f70a5c7-5ec8-405a-9c72-2b0e4f4f17c2",
   "metadata": {
    "id": "5f70a5c7-5ec8-405a-9c72-2b0e4f4f17c2",
    "outputId": "c7664303-c670-4135-d9ef-4b63d4e81e2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\l_alm\\resnet1d-master\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\l_alm\\resnet1d-master')  #adjust this to your base directory if needed\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "411444ef-51f5-4cfd-929d-88d2f5e902fc",
   "metadata": {
    "id": "411444ef-51f5-4cfd-929d-88d2f5e902fc",
    "outputId": "654f63d5-25a0-46b6-f308-54209452ccc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (2.5.1+cu121)\n",
      "Collecting torch\n",
      "  Using cached torch-2.6.0-cp39-cp39-win_amd64.whl.metadata (28 kB)\n",
      "Requirement already satisfied: torchvision in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (0.20.1+cu121)\n",
      "Collecting torchvision\n",
      "  Using cached torchvision-0.21.0-cp39-cp39-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Using cached torch-2.6.0-cp39-cp39-win_amd64.whl (204.1 MB)\n",
      "Using cached torchvision-0.21.0-cp39-cp39-win_amd64.whl (1.6 MB)\n",
      "Installing collected packages: torch, torchvision\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.5.1+cu121\n",
      "    Uninstalling torch-2.5.1+cu121:\n",
      "      Successfully uninstalled torch-2.5.1+cu121\n",
      "  Attempting uninstall: torchvision\n",
      "    Found existing installation: torchvision 0.20.1+cu121\n",
      "    Uninstalling torchvision-0.20.1+cu121:\n",
      "      Successfully uninstalled torchvision-0.20.1+cu121\n",
      "Successfully installed torch-2.6.0 torchvision-0.21.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  WARNING: Failed to remove contents in a temporary directory 'C:\\Users\\l_alm\\miniconda3\\envs\\pytorch_env\\Lib\\site-packages\\~-rch'.\n",
      "  You can safely remove it manually.\n",
      "ERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchaudio 2.5.1+cu121 requires torch==2.5.1+cu121, but you have torch 2.6.0 which is incompatible.\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f61bdc73-0704-4932-b662-62a293f7ad43",
   "metadata": {
    "id": "f61bdc73-0704-4932-b662-62a293f7ad43",
    "outputId": "7354311e-c02b-4de3-df3a-5a9e9f589dac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (2.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24da069c-00bc-4b60-ae1e-788d0c6bb5d7",
   "metadata": {
    "id": "24da069c-00bc-4b60-ae1e-788d0c6bb5d7",
    "outputId": "662e16aa-4932-4982-9521-03e6e9f138fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.30)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.69.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.4.30)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.13.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.37.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "503a27db-97b0-49d5-917e-a7cc6d9847f0",
   "metadata": {
    "id": "503a27db-97b0-49d5-917e-a7cc6d9847f0",
    "outputId": "d3f4f23d-644f-4217-c639-aee3a66fc33f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported pad_sequences from TensorFlow Keras\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "print(\"Successfully imported pad_sequences from TensorFlow Keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UtdqZhtVdcoS",
   "metadata": {
    "id": "UtdqZhtVdcoS"
   },
   "source": [
    "# checkng if there is enough memory for training\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eba9e127-5541-4791-8488-0a6eae305f3b",
   "metadata": {
    "id": "eba9e127-5541-4791-8488-0a6eae305f3b",
    "outputId": "a3692b23-cef8-4789-f2e4-ecce11cb9036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available memory: 1.62 GB\n",
      "Total memory: 16.94 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "memory = psutil.virtual_memory()\n",
    "print(f\"Available memory: {memory.available / 1e9:.2f} GB\")\n",
    "print(f\"Total memory: {memory.total / 1e9:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2da8bf55-1aa5-4323-921b-4c758fa453cd",
   "metadata": {
    "id": "2da8bf55-1aa5-4323-921b-4c758fa453cd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def read_data_generated(n_samples, n_length, n_channel, n_classes, verbose=False):\n",
    "    \"\"\"\n",
    "    Generated data\n",
    "\n",
    "    This generated data contains one noise channel class, plus unlimited number of sine channel classes which are different on frequency.\n",
    "\n",
    "    \"\"\"\n",
    "    all_X = []\n",
    "    all_Y = []\n",
    "\n",
    "    # noise channel class\n",
    "    X_noise = np.random.rand(n_samples, n_channel, n_length)\n",
    "    Y_noise = np.array([0]*n_samples)\n",
    "    all_X.append(X_noise)\n",
    "    all_Y.append(Y_noise)\n",
    "\n",
    "    # sine channel classe\n",
    "    x = np.arange(n_length)\n",
    "    for i_class in range(n_classes-1):\n",
    "        scale = 2**i_class\n",
    "        offset_list = 2*np.pi*np.random.rand(n_samples)\n",
    "        X_sin = []\n",
    "        for i_sample in range(n_samples):\n",
    "            tmp_x = []\n",
    "            for i_channel in range(n_channel):\n",
    "                tmp_x.append(np.sin(x/scale+2*np.pi*np.random.rand()))\n",
    "            X_sin.append(tmp_x)\n",
    "        X_sin = np.array(X_sin)\n",
    "        Y_sin = np.array([i_class+1]*n_samples)\n",
    "        all_X.append(X_sin)\n",
    "        all_Y.append(Y_sin)\n",
    "\n",
    "    # combine and shuffle\n",
    "    all_X = np.concatenate(all_X)\n",
    "    all_Y = np.concatenate(all_Y)\n",
    "    shuffle_idx = np.random.permutation(all_Y.shape[0])\n",
    "    all_X = all_X[shuffle_idx]\n",
    "    all_Y = all_Y[shuffle_idx]\n",
    "\n",
    "    # random pick some and plot\n",
    "    if verbose:\n",
    "        for _ in np.random.permutation(all_Y.shape[0])[:10]:\n",
    "            fig = plt.figure()\n",
    "            plt.plot(all_X[_,0,:])\n",
    "            plt.title('Label: {0}'.format(all_Y[_]))\n",
    "\n",
    "    return all_X, all_Y\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "  #  read_data_physionet_2_clean_federated(m_clients=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K1rl1xPfd2k1",
   "metadata": {
    "id": "K1rl1xPfd2k1"
   },
   "source": [
    "# 1d resnet model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "66139199-e043-42d1-9b1f-4c612df9656a",
   "metadata": {
    "id": "66139199-e043-42d1-9b1f-4c612df9656a"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "resnet for 1-d signal data, pytorch version\n",
    "\n",
    "Shenda Hong, Oct 2019\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (torch.tensor(self.data[index], dtype=torch.float), torch.tensor(self.label[index], dtype=torch.long))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class MyConv1dPadSame(nn.Module):\n",
    "    \"\"\"\n",
    "    extend nn.Conv1d to support SAME padding\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups=1):\n",
    "        super(MyConv1dPadSame, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.conv = torch.nn.Conv1d(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            groups=self.groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        net = x\n",
    "\n",
    "        # compute pad shape\n",
    "        in_dim = net.shape[-1]\n",
    "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
    "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
    "        pad_left = p // 2\n",
    "        pad_right = p - pad_left\n",
    "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
    "\n",
    "        net = self.conv(net)\n",
    "\n",
    "        return net\n",
    "\n",
    "class MyMaxPool1dPadSame(nn.Module):\n",
    "    \"\"\"\n",
    "    extend nn.MaxPool1d to support SAME padding\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(MyMaxPool1dPadSame, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = 1\n",
    "        self.max_pool = torch.nn.MaxPool1d(kernel_size=self.kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        net = x\n",
    "\n",
    "        # compute pad shape\n",
    "        in_dim = net.shape[-1]\n",
    "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
    "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
    "        pad_left = p // 2\n",
    "        pad_right = p - pad_left\n",
    "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
    "\n",
    "        net = self.max_pool(net)\n",
    "\n",
    "        return net\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet Basic Block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups, downsample, use_bn, use_do, is_first_block=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.downsample = downsample\n",
    "        if self.downsample:\n",
    "            self.stride = stride\n",
    "        else:\n",
    "            self.stride = 1\n",
    "        self.is_first_block = is_first_block\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "\n",
    "        # the first conv\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.do1 = nn.Dropout(p=0.5)\n",
    "        self.conv1 = MyConv1dPadSame(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=self.stride,\n",
    "            groups=self.groups)\n",
    "\n",
    "        # the second conv\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.do2 = nn.Dropout(p=0.5)\n",
    "        self.conv2 = MyConv1dPadSame(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            groups=self.groups)\n",
    "\n",
    "        self.max_pool = MyMaxPool1dPadSame(kernel_size=self.stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x\n",
    "\n",
    "        # the first conv\n",
    "        out = x\n",
    "        if not self.is_first_block:\n",
    "            if self.use_bn:\n",
    "                out = self.bn1(out)\n",
    "            out = self.relu1(out)\n",
    "            if self.use_do:\n",
    "                out = self.do1(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        # the second conv\n",
    "        if self.use_bn:\n",
    "            out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        if self.use_do:\n",
    "            out = self.do2(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        # if downsample, also downsample identity\n",
    "        if self.downsample:\n",
    "            identity = self.max_pool(identity)\n",
    "\n",
    "        # if expand channel, also pad zeros to identity\n",
    "        if self.out_channels != self.in_channels:\n",
    "            identity = identity.transpose(-1,-2)\n",
    "            ch1 = (self.out_channels-self.in_channels)//2\n",
    "            ch2 = self.out_channels-self.in_channels-ch1\n",
    "            identity = F.pad(identity, (ch1, ch2), \"constant\", 0)\n",
    "            identity = identity.transpose(-1,-2)\n",
    "\n",
    "        # shortcut\n",
    "        out += identity\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet1D(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    Input:\n",
    "        X: (n_samples, n_channel, n_length)\n",
    "        Y: (n_samples)\n",
    "\n",
    "    Output:\n",
    "        out: (n_samples)\n",
    "\n",
    "    Pararmetes:\n",
    "        in_channels: dim of input, the same as n_channel\n",
    "        base_filters: number of filters in the first several Conv layer, it will double at every 4 layers\n",
    "        kernel_size: width of kernel\n",
    "        stride: stride of kernel moving\n",
    "        groups: set larget to 1 as ResNeXt\n",
    "        n_block: number of blocks\n",
    "        n_classes: number of classes\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, base_filters, kernel_size, stride, groups, n_block, n_classes, downsample_gap=2, increasefilter_gap=4, use_bn=True, use_do=True, verbose=False):\n",
    "        super(ResNet1D, self).__init__()\n",
    "\n",
    "        self.verbose = verbose\n",
    "        self.n_block = n_block\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "\n",
    "        self.downsample_gap = downsample_gap # 2 for base model\n",
    "        self.increasefilter_gap = increasefilter_gap # 4 for base model\n",
    "\n",
    "        # first block\n",
    "        self.first_block_conv = MyConv1dPadSame(in_channels=in_channels, out_channels=base_filters, kernel_size=self.kernel_size, stride=1)\n",
    "        self.first_block_bn = nn.BatchNorm1d(base_filters)\n",
    "        self.first_block_relu = nn.ReLU()\n",
    "        out_channels = base_filters\n",
    "\n",
    "        # residual blocks\n",
    "        self.basicblock_list = nn.ModuleList()\n",
    "        for i_block in range(self.n_block):\n",
    "            # is_first_block\n",
    "            if i_block == 0:\n",
    "                is_first_block = True\n",
    "            else:\n",
    "                is_first_block = False\n",
    "            # downsample at every self.downsample_gap blocks\n",
    "            if i_block % self.downsample_gap == 1:\n",
    "                downsample = True\n",
    "            else:\n",
    "                downsample = False\n",
    "            # in_channels and out_channels\n",
    "            if is_first_block:\n",
    "                in_channels = base_filters\n",
    "                out_channels = in_channels\n",
    "            else:\n",
    "                # increase filters at every self.increasefilter_gap blocks\n",
    "                in_channels = int(base_filters*2**((i_block-1)//self.increasefilter_gap))\n",
    "                if (i_block % self.increasefilter_gap == 0) and (i_block != 0):\n",
    "                    out_channels = in_channels * 2\n",
    "                else:\n",
    "                    out_channels = in_channels\n",
    "\n",
    "            tmp_block = BasicBlock(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=self.kernel_size,\n",
    "                stride = self.stride,\n",
    "                groups = self.groups,\n",
    "                downsample=downsample,\n",
    "                use_bn = self.use_bn,\n",
    "                use_do = self.use_do,\n",
    "                is_first_block=is_first_block)\n",
    "            self.basicblock_list.append(tmp_block)\n",
    "\n",
    "        # final prediction\n",
    "        self.final_bn = nn.BatchNorm1d(out_channels)\n",
    "        self.final_relu = nn.ReLU(inplace=True)\n",
    "        # self.do = nn.Dropout(p=0.5)\n",
    "        self.dense = nn.Linear(out_channels, n_classes)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = x\n",
    "\n",
    "        # first conv\n",
    "        if self.verbose:\n",
    "            print('input shape', out.shape)\n",
    "        out = self.first_block_conv(out)\n",
    "        if self.verbose:\n",
    "            print('after first conv', out.shape)\n",
    "        if self.use_bn:\n",
    "            out = self.first_block_bn(out)\n",
    "        out = self.first_block_relu(out)\n",
    "\n",
    "        # residual blocks, every block has two conv\n",
    "        for i_block in range(self.n_block):\n",
    "            net = self.basicblock_list[i_block]\n",
    "            if self.verbose:\n",
    "                print('i_block: {0}, in_channels: {1}, out_channels: {2}, downsample: {3}'.format(i_block, net.in_channels, net.out_channels, net.downsample))\n",
    "            out = net(out)\n",
    "            if self.verbose:\n",
    "                print(out.shape)\n",
    "\n",
    "        # final prediction\n",
    "        if self.use_bn:\n",
    "            out = self.final_bn(out)\n",
    "        out = self.final_relu(out)\n",
    "        out = out.mean(-1)\n",
    "        if self.verbose:\n",
    "            print('final pooling', out.shape)\n",
    "        # out = self.do(out)\n",
    "        out = self.dense(out)\n",
    "        if self.verbose:\n",
    "            print('dense', out.shape)\n",
    "        # out = self.softmax(out)\n",
    "        if self.verbose:\n",
    "            print('softmax', out.shape)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "80fe173f-caa7-42d5-bcc6-ea2e8d3c1343",
   "metadata": {
    "id": "80fe173f-caa7-42d5-bcc6-ea2e8d3c1343"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "resnet for 1-d signal data, pytorch version\n",
    "\n",
    "Shenda Hong, Oct 2019\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (torch.tensor(self.data[index], dtype=torch.float), torch.tensor(self.label[index], dtype=torch.long))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class MyConv1dPadSame(nn.Module):\n",
    "    \"\"\"\n",
    "    extend nn.Conv1d to support SAME padding\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups=1):\n",
    "        super(MyConv1dPadSame, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.conv = torch.nn.Conv1d(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            groups=self.groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        net = x\n",
    "\n",
    "        # compute pad shape\n",
    "        in_dim = net.shape[-1]\n",
    "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
    "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
    "        pad_left = p // 2\n",
    "        pad_right = p - pad_left\n",
    "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
    "\n",
    "        net = self.conv(net)\n",
    "\n",
    "        return net\n",
    "\n",
    "class MyMaxPool1dPadSame(nn.Module):\n",
    "    \"\"\"\n",
    "    extend nn.MaxPool1d to support SAME padding\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(MyMaxPool1dPadSame, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = 1\n",
    "        self.max_pool = torch.nn.MaxPool1d(kernel_size=self.kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        net = x\n",
    "\n",
    "        # compute pad shape\n",
    "        in_dim = net.shape[-1]\n",
    "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
    "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
    "        pad_left = p // 2\n",
    "        pad_right = p - pad_left\n",
    "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
    "\n",
    "        net = self.max_pool(net)\n",
    "\n",
    "        return net\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet Basic Block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups, downsample, use_bn, use_do, is_first_block=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.downsample = downsample\n",
    "        if self.downsample:\n",
    "            self.stride = stride\n",
    "        else:\n",
    "            self.stride = 1\n",
    "        self.is_first_block = is_first_block\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "\n",
    "        # the first conv\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.do1 = nn.Dropout(p=0.5)\n",
    "        self.conv1 = MyConv1dPadSame(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=self.stride,\n",
    "            groups=self.groups)\n",
    "\n",
    "        # the second conv\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.do2 = nn.Dropout(p=0.5)\n",
    "        self.conv2 = MyConv1dPadSame(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            groups=self.groups)\n",
    "\n",
    "        self.max_pool = MyMaxPool1dPadSame(kernel_size=self.stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x\n",
    "\n",
    "        # the first conv\n",
    "        out = x\n",
    "        if not self.is_first_block:\n",
    "            if self.use_bn:\n",
    "                out = self.bn1(out)\n",
    "            out = self.relu1(out)\n",
    "            if self.use_do:\n",
    "                out = self.do1(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        # the second conv\n",
    "        if self.use_bn:\n",
    "            out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        if self.use_do:\n",
    "            out = self.do2(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        # if downsample, also downsample identity\n",
    "        if self.downsample:\n",
    "            identity = self.max_pool(identity)\n",
    "\n",
    "        # if expand channel, also pad zeros to identity\n",
    "        if self.out_channels != self.in_channels:\n",
    "            identity = identity.transpose(-1,-2)\n",
    "            ch1 = (self.out_channels-self.in_channels)//2\n",
    "            ch2 = self.out_channels-self.in_channels-ch1\n",
    "            identity = F.pad(identity, (ch1, ch2), \"constant\", 0)\n",
    "            identity = identity.transpose(-1,-2)\n",
    "\n",
    "        # shortcut\n",
    "        out += identity\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet1D(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    Input:\n",
    "        X: (n_samples, n_channel, n_length)\n",
    "        Y: (n_samples)\n",
    "\n",
    "    Output:\n",
    "        out: (n_samples)\n",
    "\n",
    "    Pararmetes:\n",
    "        in_channels: dim of input, the same as n_channel\n",
    "        base_filters: number of filters in the first several Conv layer, it will double at every 4 layers\n",
    "        kernel_size: width of kernel\n",
    "        stride: stride of kernel moving\n",
    "        groups: set larget to 1 as ResNeXt\n",
    "        n_block: number of blocks\n",
    "        n_classes: number of classes\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, base_filters, kernel_size, stride, groups, n_block, n_classes, downsample_gap=2, increasefilter_gap=4, use_bn=True, use_do=True, verbose=False):\n",
    "        super(ResNet1D, self).__init__()\n",
    "\n",
    "        self.verbose = verbose\n",
    "        self.n_block = n_block\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "\n",
    "        self.downsample_gap = downsample_gap # 2 for base model\n",
    "        self.increasefilter_gap = increasefilter_gap # 4 for base model\n",
    "\n",
    "        # first block\n",
    "        self.first_block_conv = MyConv1dPadSame(in_channels=in_channels, out_channels=base_filters, kernel_size=self.kernel_size, stride=1)\n",
    "        self.first_block_bn = nn.BatchNorm1d(base_filters)\n",
    "        self.first_block_relu = nn.ReLU()\n",
    "        out_channels = base_filters\n",
    "\n",
    "        # residual blocks\n",
    "        self.basicblock_list = nn.ModuleList()\n",
    "        for i_block in range(self.n_block):\n",
    "            # is_first_block\n",
    "            if i_block == 0:\n",
    "                is_first_block = True\n",
    "            else:\n",
    "                is_first_block = False\n",
    "            # downsample at every self.downsample_gap blocks\n",
    "            if i_block % self.downsample_gap == 1:\n",
    "                downsample = True\n",
    "            else:\n",
    "                downsample = False\n",
    "            # in_channels and out_channels\n",
    "            if is_first_block:\n",
    "                in_channels = base_filters\n",
    "                out_channels = in_channels\n",
    "            else:\n",
    "                # increase filters at every self.increasefilter_gap blocks\n",
    "                in_channels = int(base_filters*2**((i_block-1)//self.increasefilter_gap))\n",
    "                if (i_block % self.increasefilter_gap == 0) and (i_block != 0):\n",
    "                    out_channels = in_channels * 2\n",
    "                else:\n",
    "                    out_channels = in_channels\n",
    "\n",
    "            tmp_block = BasicBlock(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=self.kernel_size,\n",
    "                stride = self.stride,\n",
    "                groups = self.groups,\n",
    "                downsample=downsample,\n",
    "                use_bn = self.use_bn,\n",
    "                use_do = self.use_do,\n",
    "                is_first_block=is_first_block)\n",
    "            self.basicblock_list.append(tmp_block)\n",
    "\n",
    "        # final prediction\n",
    "        self.final_bn = nn.BatchNorm1d(out_channels)\n",
    "        self.final_relu = nn.ReLU(inplace=True)\n",
    "        # self.do = nn.Dropout(p=0.5)\n",
    "        self.dense = nn.Linear(out_channels, n_classes)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = x\n",
    "\n",
    "        # first conv\n",
    "        if self.verbose:\n",
    "            print('input shape', out.shape)\n",
    "        out = self.first_block_conv(out)\n",
    "        if self.verbose:\n",
    "            print('after first conv', out.shape)\n",
    "        if self.use_bn:\n",
    "            out = self.first_block_bn(out)\n",
    "        out = self.first_block_relu(out)\n",
    "\n",
    "        # residual blocks, every block has two conv\n",
    "        for i_block in range(self.n_block):\n",
    "            net = self.basicblock_list[i_block]\n",
    "            if self.verbose:\n",
    "                print('i_block: {0}, in_channels: {1}, out_channels: {2}, downsample: {3}'.format(i_block, net.in_channels, net.out_channels, net.downsample))\n",
    "            out = net(out)\n",
    "            if self.verbose:\n",
    "                print(out.shape)\n",
    "\n",
    "        # final prediction\n",
    "        if self.use_bn:\n",
    "            out = self.final_bn(out)\n",
    "        out = self.final_relu(out)\n",
    "        out = out.mean(-1)\n",
    "        if self.verbose:\n",
    "            print('final pooling', out.shape)\n",
    "        # out = self.do(out)\n",
    "        out = self.dense(out)\n",
    "        if self.verbose:\n",
    "            print('dense', out.shape)\n",
    "        # out = self.softmax(out)\n",
    "        if self.verbose:\n",
    "            print('softmax', out.shape)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74f7f7a6-3fe1-4679-b7c3-c77ae9f64ed5",
   "metadata": {
    "id": "74f7f7a6-3fe1-4679-b7c3-c77ae9f64ed5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def read_data_generated(n_samples, n_length, n_channel, n_classes, verbose=False):\n",
    "    \"\"\"\n",
    "    Generated data\n",
    "\n",
    "    This generated data contains one noise channel class, plus unlimited number of sine channel classes which are different on frequency.\n",
    "\n",
    "    \"\"\"\n",
    "    all_X = []\n",
    "    all_Y = []\n",
    "\n",
    "    # noise channel class\n",
    "    X_noise = np.random.rand(n_samples, n_channel, n_length)\n",
    "    Y_noise = np.array([0]*n_samples)\n",
    "    all_X.append(X_noise)\n",
    "    all_Y.append(Y_noise)\n",
    "\n",
    "    # sine channel classe\n",
    "    x = np.arange(n_length)\n",
    "    for i_class in range(n_classes-1):\n",
    "        scale = 2**i_class\n",
    "        offset_list = 2*np.pi*np.random.rand(n_samples)\n",
    "        X_sin = []\n",
    "        for i_sample in range(n_samples):\n",
    "            tmp_x = []\n",
    "            for i_channel in range(n_channel):\n",
    "                tmp_x.append(np.sin(x/scale+2*np.pi*np.random.rand()))\n",
    "            X_sin.append(tmp_x)\n",
    "        X_sin = np.array(X_sin)\n",
    "        Y_sin = np.array([i_class+1]*n_samples)\n",
    "        all_X.append(X_sin)\n",
    "        all_Y.append(Y_sin)\n",
    "\n",
    "    # combine and shuffle\n",
    "    all_X = np.concatenate(all_X)\n",
    "    all_Y = np.concatenate(all_Y)\n",
    "    shuffle_idx = np.random.permutation(all_Y.shape[0])\n",
    "    all_X = all_X[shuffle_idx]\n",
    "    all_Y = all_Y[shuffle_idx]\n",
    "\n",
    "    # random pick some and plot\n",
    "    if verbose:\n",
    "        for _ in np.random.permutation(all_Y.shape[0])[:10]:\n",
    "            fig = plt.figure()\n",
    "            plt.plot(all_X[_,0,:])\n",
    "            plt.title('Label: {0}'.format(all_Y[_]))\n",
    "\n",
    "    return all_X, all_Y\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "  #  read_data_physionet_2_clean_federated(m_clients=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "994b7f0e-e887-425f-b52a-6e9a71ef10c9",
   "metadata": {
    "id": "994b7f0e-e887-425f-b52a-6e9a71ef10c9",
    "outputId": "c239a1f3-f1ad-44c8-efa7-f2e377c247d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboardX in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboardX) (1.23.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboardX) (24.2)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboardX) (4.25.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nJikrHgWeIMu",
   "metadata": {
    "id": "nJikrHgWeIMu"
   },
   "source": [
    "# Preprocessing functions are in another file preprocessing.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e927808-41fd-48b1-b552-e3a7aa60d00b",
   "metadata": {
    "id": "9e927808-41fd-48b1-b552-e3a7aa60d00b",
    "outputId": "2c95209c-2cf5-4ad2-cddf-03628242d286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from imbalanced-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JyusqUmueZL9",
   "metadata": {
    "id": "JyusqUmueZL9"
   },
   "source": [
    "# Model Training and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8f267a5f-e67e-45c8-978c-f7091ad4b84d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found existing installation: torch 2.6.0\n",
      "Uninstalling torch-2.6.0:\n",
      "  Successfully uninstalled torch-2.6.0\n",
      "Found existing installation: torchvision 0.21.0\n",
      "Uninstalling torchvision-0.21.0:\n",
      "  Successfully uninstalled torchvision-0.21.0\n",
      "Found existing installation: torchaudio 2.5.1+cu121\n",
      "Uninstalling torchaudio-2.5.1+cu121:\n",
      "  Successfully uninstalled torchaudio-2.5.1+cu121\n",
      "Looking in indexes: https://download.pytorch.org/whl/cu121\n",
      "Collecting torch\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torch-2.5.1%2Bcu121-cp39-cp39-win_amd64.whl (2449.3 MB)\n",
      "Collecting torchvision\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchvision-0.20.1%2Bcu121-cp39-cp39-win_amd64.whl (6.1 MB)\n",
      "Collecting torchaudio\n",
      "  Using cached https://download.pytorch.org/whl/cu121/torchaudio-2.5.1%2Bcu121-cp39-cp39-win_amd64.whl (4.1 MB)\n",
      "Requirement already satisfied: filelock in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torchvision) (10.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from jinja2->torch) (2.1.3)\n",
      "Installing collected packages: torch, torchvision, torchaudio\n",
      "Successfully installed torch-2.5.1+cu121 torchaudio-2.5.1+cu121 torchvision-0.20.1+cu121\n"
     ]
    }
   ],
   "source": [
    "!pip uninstall torch torchvision torchaudio -y\n",
    "!pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu121\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ab831208-05f4-48e1-acad-86205d2c3e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchinfo in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (1.8.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchinfo\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bd02bc3f-d764-47d0-afdc-e3849aa76f8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fvcore in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (0.1.5.post20221221)\n",
      "Requirement already satisfied: numpy in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from fvcore) (1.23.5)\n",
      "Requirement already satisfied: yacs>=0.1.6 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from fvcore) (0.1.8)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from fvcore) (6.0.2)\n",
      "Requirement already satisfied: tqdm in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from fvcore) (4.67.1)\n",
      "Requirement already satisfied: termcolor>=1.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from fvcore) (2.5.0)\n",
      "Requirement already satisfied: Pillow in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from fvcore) (10.3.0)\n",
      "Requirement already satisfied: tabulate in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from fvcore) (0.9.0)\n",
      "Requirement already satisfied: iopath>=0.1.7 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from fvcore) (0.1.10)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from iopath>=0.1.7->fvcore) (4.12.2)\n",
      "Requirement already satisfied: portalocker in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from iopath>=0.1.7->fvcore) (3.1.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tqdm->fvcore) (0.4.6)\n",
      "Requirement already satisfied: pywin32>=226 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from portalocker->iopath>=0.1.7->fvcore) (307)\n"
     ]
    }
   ],
   "source": [
    "!pip install fvcore\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad12eba8-a11f-4602-96fc-e6f290acffc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "ad12eba8-a11f-4602-96fc-e6f290acffc6",
    "outputId": "0618c421-e9e7-4868-ad11-6780ee349b16"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6620, 70, 1) Counter({1: 3076, 2: 1877, 0: 1667})\n",
      "Train size: 3972, Validation size: 1324, Test size: 1324\n",
      "Train batches: 32, Validation batches: 11, Test batches: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsupported operator aten::add encountered 210 time(s)\n",
      "Unsupported operator aten::sub encountered 420 time(s)\n",
      "Unsupported operator aten::mul encountered 105 time(s)\n",
      "Unsupported operator aten::pad encountered 108 time(s)\n",
      "Unsupported operator aten::add_ encountered 145 time(s)\n",
      "Unsupported operator aten::max_pool1d encountered 8 time(s)\n",
      "Unsupported operator aten::mean encountered 1 time(s)\n",
      "The following submodules of the model were never called during the trace of the graph. They may be unused, or they were accessed by direct calls to .forward() or via other python methods. In the latter case they will have zeros for statistics, though their statistics will still contribute to their parent calling module.\n",
      "basicblock_list.0.bn1, basicblock_list.0.do1, basicblock_list.0.max_pool, basicblock_list.0.max_pool.max_pool, basicblock_list.0.relu1, basicblock_list.10.max_pool, basicblock_list.10.max_pool.max_pool, basicblock_list.11.max_pool, basicblock_list.11.max_pool.max_pool, basicblock_list.12.max_pool, basicblock_list.12.max_pool.max_pool, basicblock_list.14.max_pool, basicblock_list.14.max_pool.max_pool, basicblock_list.15.max_pool, basicblock_list.15.max_pool.max_pool, basicblock_list.16.max_pool, basicblock_list.16.max_pool.max_pool, basicblock_list.17.max_pool, basicblock_list.17.max_pool.max_pool, basicblock_list.18.max_pool, basicblock_list.18.max_pool.max_pool, basicblock_list.2.max_pool, basicblock_list.2.max_pool.max_pool, basicblock_list.20.max_pool, basicblock_list.20.max_pool.max_pool, basicblock_list.21.max_pool, basicblock_list.21.max_pool.max_pool, basicblock_list.22.max_pool, basicblock_list.22.max_pool.max_pool, basicblock_list.23.max_pool, basicblock_list.23.max_pool.max_pool, basicblock_list.24.max_pool, basicblock_list.24.max_pool.max_pool, basicblock_list.26.max_pool, basicblock_list.26.max_pool.max_pool, basicblock_list.27.max_pool, basicblock_list.27.max_pool.max_pool, basicblock_list.28.max_pool, basicblock_list.28.max_pool.max_pool, basicblock_list.29.max_pool, basicblock_list.29.max_pool.max_pool, basicblock_list.3.max_pool, basicblock_list.3.max_pool.max_pool, basicblock_list.30.max_pool, basicblock_list.30.max_pool.max_pool, basicblock_list.32.max_pool, basicblock_list.32.max_pool.max_pool, basicblock_list.33.max_pool, basicblock_list.33.max_pool.max_pool, basicblock_list.34.max_pool, basicblock_list.34.max_pool.max_pool, basicblock_list.35.max_pool, basicblock_list.35.max_pool.max_pool, basicblock_list.36.max_pool, basicblock_list.36.max_pool.max_pool, basicblock_list.38.max_pool, basicblock_list.38.max_pool.max_pool, basicblock_list.39.max_pool, basicblock_list.39.max_pool.max_pool, basicblock_list.4.max_pool, basicblock_list.4.max_pool.max_pool, basicblock_list.40.max_pool, basicblock_list.40.max_pool.max_pool, basicblock_list.41.max_pool, basicblock_list.41.max_pool.max_pool, basicblock_list.42.max_pool, basicblock_list.42.max_pool.max_pool, basicblock_list.44.max_pool, basicblock_list.44.max_pool.max_pool, basicblock_list.45.max_pool, basicblock_list.45.max_pool.max_pool, basicblock_list.46.max_pool, basicblock_list.46.max_pool.max_pool, basicblock_list.47.max_pool, basicblock_list.47.max_pool.max_pool, basicblock_list.5.max_pool, basicblock_list.5.max_pool.max_pool, basicblock_list.6.max_pool, basicblock_list.6.max_pool.max_pool, basicblock_list.8.max_pool, basicblock_list.8.max_pool.max_pool, basicblock_list.9.max_pool, basicblock_list.9.max_pool.max_pool\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "فotal FLOPs: 8,561,280\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Train Loss = 37.0039, Train F1 = 0.3597\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: Val Loss = 12.0174, Val F1 = 0.3111\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Train Loss = 36.0165, Train F1 = 0.3724\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: Val Loss = 11.8955, Val F1 = 0.3978\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Train Loss = 35.8279, Train F1 = 0.3824\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: Val Loss = 11.8089, Val F1 = 0.3927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Train Loss = 35.5341, Train F1 = 0.3874\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: Val Loss = 11.7129, Val F1 = 0.4373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Train Loss = 35.6348, Train F1 = 0.3812\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: Val Loss = 11.6690, Val F1 = 0.4348\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Train Loss = 35.3987, Train F1 = 0.4198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: Val Loss = 11.6400, Val F1 = 0.4342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Train Loss = 34.7301, Train F1 = 0.4192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: Val Loss = 11.5586, Val F1 = 0.4329\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Train Loss = 34.7059, Train F1 = 0.4384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: Val Loss = 11.5417, Val F1 = 0.4287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Train Loss = 34.5580, Train F1 = 0.4283\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: Val Loss = 11.4886, Val F1 = 0.4259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Train Loss = 34.2874, Train F1 = 0.4471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: Val Loss = 11.4453, Val F1 = 0.4327\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Train Loss = 34.1795, Train F1 = 0.4411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: Val Loss = 11.4191, Val F1 = 0.4594\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Train Loss = 34.4924, Train F1 = 0.4333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: Val Loss = 11.3748, Val F1 = 0.4560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Train Loss = 34.1537, Train F1 = 0.4337\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: Val Loss = 11.3888, Val F1 = 0.4735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Train Loss = 34.0696, Train F1 = 0.4403\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: Val Loss = 11.3607, Val F1 = 0.4764\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Train Loss = 34.0805, Train F1 = 0.4649\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: Val Loss = 11.3357, Val F1 = 0.4793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Train Loss = 34.1632, Train F1 = 0.4487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: Val Loss = 11.3039, Val F1 = 0.4772\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Train Loss = 33.6480, Train F1 = 0.4637\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: Val Loss = 11.3017, Val F1 = 0.4838\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Train Loss = 33.8752, Train F1 = 0.4610\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: Val Loss = 11.2483, Val F1 = 0.4691\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Train Loss = 33.9335, Train F1 = 0.4631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: Val Loss = 11.2168, Val F1 = 0.4786\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Train Loss = 33.5824, Train F1 = 0.4746\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: Val Loss = 11.2263, Val F1 = 0.4971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Train Loss = 33.5617, Train F1 = 0.4668\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: Val Loss = 11.2199, Val F1 = 0.4905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Train Loss = 33.5976, Train F1 = 0.4560\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: Val Loss = 11.1689, Val F1 = 0.4694\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Train Loss = 33.8051, Train F1 = 0.4723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: Val Loss = 11.1316, Val F1 = 0.4839\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Train Loss = 33.6735, Train F1 = 0.4774\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: Val Loss = 11.1444, Val F1 = 0.4870\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Train Loss = 32.9514, Train F1 = 0.4791\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25: Val Loss = 11.1024, Val F1 = 0.4929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Train Loss = 33.0581, Train F1 = 0.4733\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26: Val Loss = 11.0735, Val F1 = 0.4856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Train Loss = 33.1651, Train F1 = 0.4855\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27: Val Loss = 11.0746, Val F1 = 0.4889\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Train Loss = 33.6065, Train F1 = 0.4775\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28: Val Loss = 11.0740, Val F1 = 0.4937\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Train Loss = 33.2713, Train F1 = 0.4835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29: Val Loss = 11.0478, Val F1 = 0.4831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Train Loss = 33.2152, Train F1 = 0.4781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30: Val Loss = 11.0458, Val F1 = 0.4989\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Train Loss = 32.8911, Train F1 = 0.4794\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31: Val Loss = 11.0653, Val F1 = 0.4908\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Train Loss = 32.8254, Train F1 = 0.5005\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32: Val Loss = 11.0047, Val F1 = 0.5025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Train Loss = 33.4513, Train F1 = 0.4813\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33: Val Loss = 10.9643, Val F1 = 0.5040\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Train Loss = 33.4534, Train F1 = 0.4836\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34: Val Loss = 10.9612, Val F1 = 0.5043\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Train Loss = 32.5302, Train F1 = 0.4914\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35: Val Loss = 10.9588, Val F1 = 0.5054\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Train Loss = 32.7633, Train F1 = 0.4920\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36: Val Loss = 10.9797, Val F1 = 0.5115\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Train Loss = 33.2724, Train F1 = 0.4901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37: Val Loss = 10.9245, Val F1 = 0.5072\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Train Loss = 32.7409, Train F1 = 0.5051\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38: Val Loss = 10.9173, Val F1 = 0.5087\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Train Loss = 32.8688, Train F1 = 0.4832\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39: Val Loss = 10.9113, Val F1 = 0.5031\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Train Loss = 32.8594, Train F1 = 0.4905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40: Val Loss = 10.9072, Val F1 = 0.5020\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Train Loss = 32.6179, Train F1 = 0.4868\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                                                                                           "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41: Val Loss = 10.8945, Val F1 = 0.5042\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training Epoch 42:  56%|███████████████████████████████████████████████████████▋                                           | 18/32 [00:07<00:05,  2.42it/s]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "from preprocessing import preprocess_data #adjust this if using preprocess_data_with_smote\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from fvcore.nn import FlopCountAnalysis, parameter_count_table\n",
    "from torchinfo import summary  #for model summary\n",
    "\n",
    "#load and preprocess data\n",
    "#data, label = preprocess_data_with_smote(r'C:\\Users\\l_alm\\resnet1d-master\\content\\customerTargeting.csv')\n",
    "data, label = preprocess_data(r'C:\\Users\\l_alm\\resnet1d-master\\content\\customerTargeting.csv')\n",
    "print(data.shape, Counter(label))\n",
    "dataset = MyDataset(data, label)\n",
    "\n",
    "#split dataset and prepare DataLoaders\n",
    "#calculate split sizes 60,20,20\n",
    "total_size = len(dataset)\n",
    "train_size = int(0.6 * total_size)\n",
    "val_size = int(0.2 * total_size)\n",
    "test_size = total_size - train_size - val_size  #checking\n",
    "# Print split sizes\n",
    "print(f\"Train size: {train_size}, Validation size: {val_size}, Test size: {test_size}\")\n",
    "# split dataset\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_set, batch_size=128, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=128, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=128, shuffle=False)\n",
    "print(f\"Train batches: {len(train_loader)}, Validation batches: {len(val_loader)}, Test batches: {len(test_loader)}\")\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_classes = 3\n",
    "\n",
    "model = ResNet1D(\n",
    "    in_channels=70, #NO of features\n",
    "    base_filters=64,#on the authors github repository he added a comment that 64 is for resnet1d\n",
    "    kernel_size=16, \n",
    "    stride=2,\n",
    "    n_block=48,\n",
    "    groups=32,\n",
    "    n_classes=n_classes,\n",
    "    downsample_gap=6,#downsampling happens at every block ->  increases the efficiency of feature compression\n",
    "    increasefilter_gap=12,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "#compute FLOPs before training\n",
    "iinput = torch.randn(2, 70, 1).to(device)  #batch size=2 bc 1 gives error features=70 sequence length=1\n",
    "#making sure all layers are used by running a forward pass\n",
    "with torch.no_grad():\n",
    "    _ = model(iinput)\n",
    "\n",
    "#compute FLOP\n",
    "flops = FlopCountAnalysis(model, iinput)\n",
    "print(f\"total FLOPs: {flops.total():,}\")\n",
    "\n",
    "\n",
    "#optimizer loss function and scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4, weight_decay=1e-4)  # learning rate\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(label), y=label)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "#early stopping parameters\n",
    "early_stopping_patience = 20\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "#training settings\n",
    "n_epoch = 200\n",
    "\n",
    "# Training and validation loop\n",
    "for epoch in range(n_epoch):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    all_train_labels = []\n",
    "    all_train_preds = []\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\", leave=False):\n",
    "        input_x, input_y = tuple(t.to(device) for t in batch)\n",
    "        pred = model(input_x)\n",
    "        loss = loss_func(pred, input_y)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        all_train_labels.extend(input_y.cpu().numpy())\n",
    "        all_train_preds.extend(pred.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "    #compute training loss and weighted F1 score\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average='weighted')\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Train F1 = {train_f1:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval() #switch to evaluation mode (disables dropout & batch norm updates)\n",
    "    val_loss = 0\n",
    "    all_val_labels = []\n",
    "    all_val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(val_loader, desc=f\"Validation Epoch {epoch+1}\", leave=False): \n",
    "            input_x, input_y = tuple(t.to(device) for t in batch)\n",
    "            pred = model(input_x)\n",
    "            loss = loss_func(pred, input_y)\n",
    "            \n",
    "            val_loss += loss.item()\n",
    "            all_val_labels.extend(input_y.cpu().numpy())\n",
    "            all_val_preds.extend(pred.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "    #compute validation loss and F1 score\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, average='weighted')\n",
    "    print(f\"Epoch {epoch+1}: Val Loss = {val_loss:.4f}, Val F1 = {val_f1:.4f}\")\n",
    "    \n",
    "    #update lR scheduler\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")  #save best model\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "#final evaluation\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval() #switch to evaluation mode (disables dropout & batch norm updates)\n",
    "all_pred_prob = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Final Testing\", leave=False):\n",
    "           input_x, input_y = tuple(t.to(device) for t in batch)\n",
    "           pred = model(input_x)\n",
    "           all_pred_prob.append(pred.cpu().data.numpy())\n",
    "all_pred_prob = np.concatenate(all_pred_prob)\n",
    "all_pred = np.argmax(all_pred_prob, axis=1)\n",
    "\n",
    "all_test_labels = []\n",
    "for _, labels in test_loader:\n",
    "    all_test_labels.extend(labels.cpu().numpy())  # Fix here\n",
    "\n",
    "\n",
    "all_test_labels = np.array(all_test_labels)\n",
    "print(\"Test Labels:\", all_test_labels)\n",
    "print(classification_report(all_test_labels, all_pred))  #fix argument order\n",
    "print('Training complete.')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
