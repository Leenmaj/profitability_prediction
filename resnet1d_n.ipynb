{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4470a145-cc3e-45ab-8b8b-9416e9d73f96",
   "metadata": {
    "id": "4470a145-cc3e-45ab-8b8b-9416e9d73f96",
    "outputId": "350cef80-c8ce-4005-c144-671fcbd8f3fe"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (1.5.2)\n",
      "Requirement already satisfied: numpy>=1.19.5 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.6.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn) (1.13.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from scikit-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WLCZqhhZcp0g",
   "metadata": {
    "id": "WLCZqhhZcp0g"
   },
   "source": [
    "# Checking if GPU is in use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7177e503-d0b2-4c7e-8b81-42a1b25370da",
   "metadata": {
    "id": "7177e503-d0b2-4c7e-8b81-42a1b25370da",
    "outputId": "4e926011-479b-43ef-8cba-25542d112b8f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: tensorflowNote: you may need to restart the kernel to use updated packages.\n",
      "\n",
      "Version: 2.12.0\n",
      "Summary: TensorFlow is an open source machine learning framework for everyone.\n",
      "Home-page: https://www.tensorflow.org/\n",
      "Author: Google Inc.\n",
      "Author-email: packages@tensorflow.org\n",
      "License: Apache 2.0\n",
      "Location: c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages\n",
      "Requires: tensorflow-intel\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "pip show tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e464140a-a368-4bfb-9955-d6cf6645fd9c",
   "metadata": {
    "id": "e464140a-a368-4bfb-9955-d6cf6645fd9c",
    "outputId": "a4148050-62f5-461c-cac2-ab9f19e29604"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 2.12.0\n",
      "GPU Devices: []\n",
      "Local Devices: [name: \"/device:CPU:0\"\n",
      "device_type: \"CPU\"\n",
      "memory_limit: 268435456\n",
      "locality {\n",
      "}\n",
      "incarnation: 13426814924348881434\n",
      "xla_global_id: -1\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"GPU Devices:\", tf.config.list_physical_devices('GPU'))\n",
    "from tensorflow.python.client import device_lib\n",
    "print(\"Local Devices:\", device_lib.list_local_devices())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbf1d787-2f46-439d-8614-823b6795f980",
   "metadata": {
    "id": "cbf1d787-2f46-439d-8614-823b6795f980",
    "outputId": "3f3ecb27-d9fe-45eb-fa12-5c9452adee9f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.12.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7cfcc2a-2ec7-4152-a3cd-598c10f62230",
   "metadata": {
    "id": "e7cfcc2a-2ec7-4152-a3cd-598c10f62230",
    "outputId": "b9ba6cd3-fd3b-4173-a127-a83a2c912bc0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.is_available())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc272962-540f-4ae4-9a1b-aefca92133cb",
   "metadata": {
    "id": "cc272962-540f-4ae4-9a1b-aefca92133cb",
    "outputId": "ef4ab500-73e4-42bd-9803-5a819251a8fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVIDIA GeForce GTX 1660 Ti with Max-Q Design\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.cuda.get_device_name(0))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac0d9e6e-a97b-458d-a8e1-d7630dfa37ed",
   "metadata": {
    "id": "ac0d9e6e-a97b-458d-a8e1-d7630dfa37ed",
    "outputId": "f569af0c-2b66-42ca-dd05-5cbd8c95ec95"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current Working Directory: C:\\Users\\l_alm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(\"Current Working Directory:\", os.getcwd())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2788cf5b-fb41-4dd7-8b3c-ba8e8d6a247f",
   "metadata": {
    "id": "2788cf5b-fb41-4dd7-8b3c-ba8e8d6a247f",
    "outputId": "863e4c7e-347d-473d-afa0-96dee1c861f2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.anaconda', '.bash_history', '.cache', '.conda', '.condarc', '.config', '.continuum', '.dropbox_bi', '.gitconfig', '.grasp_settings', '.idlerc', '.ipynb_checkpoints', '.ipython', '.jupyter', '.keras', '.lesshst', '.m2', '.matplotlib', '.ms-ad', '.nbi', '.packettracer', '.spyder-py3', '.ssh', '.vscode', '1D-ResNet-SE-LSTM-main', '3D Objects', 'ansel', 'AppData', 'Apple', 'Application Data', 'attempt2.ipynb', 'cifar 10 classification.ipynb', 'Cisco Packet Tracer 8.2.2', 'Contacts', 'Cookies', 'CSC 340', 'cudnn-windows-x86_64-8.6.0.163_cuda11-archive', 'customerTargeting.csv', 'data', 'Documents', 'Downloads', 'Dropbox', 'ds-phase2', 'euclidean_distance.c', 'Favorites', 'fmri.mat', 'gcc', 'Homework_1.ipynb', 'IntelGraphicsProfiles', 'Jedi', 'jjjj', 'leen', 'Links', 'Local Settings', 'mingw-get-setup.exe', 'miniconda3', 'mkscancer-master', 'Music', 'My Documents', 'myenv', 'NetHood', 'NTUSER.DAT', 'ntuser.dat.LOG1', 'ntuser.dat.LOG2', 'NTUSER.DAT{2ad838bc-efea-11ee-a54d-000d3a94eaa1}.TM.blf', 'NTUSER.DAT{2ad838bc-efea-11ee-a54d-000d3a94eaa1}.TMContainer00000000000000000001.regtrans-ms', 'NTUSER.DAT{2ad838bc-efea-11ee-a54d-000d3a94eaa1}.TMContainer00000000000000000002.regtrans-ms', 'ntuser.ini', 'OneDrive', 'OneDrive - King Suad University', 'output.png', 'PrintHood', 'Recent', 'resnet1d-master', 'ResNet1D-VariableLengthPooling-For-TimeSeries-master', 'resnet1d.ipynb', 'resnet1d_n.ipynb', 'Saved Games', 'Searches', 'SendTo', 'source', 'Start Menu', 'Templates', 'tf_gpu_env', 'tut web', 'Untitled.ipynb', 'untitled.py', 'Untitled1.ipynb', 'Untitled10.ipynb', 'Untitled11.ipynb', 'Untitled12.ipynb', 'Untitled13.ipynb', 'Untitled2.ipynb', 'Untitled3.ipynb', 'Untitled4.ipynb', 'Untitled5.ipynb', 'Untitled6.ipynb', 'Untitled7.ipynb', 'Untitled8.ipynb', 'Videos', 'WLASL-master', 'WLASL100_Instances.csv']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(os.listdir())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "34f185a8-46be-45b3-9949-d1c2a616a94b",
   "metadata": {
    "id": "34f185a8-46be-45b3-9949-d1c2a616a94b",
    "outputId": "7246d400-9052-47ef-e969-5064297e18c7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tqdm in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (4.67.1)\n",
      "Requirement already satisfied: colorama in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tqdm) (0.4.6)\n"
     ]
    }
   ],
   "source": [
    "!pip install tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "84ca187e-d3a5-4250-88c5-469e662bff78",
   "metadata": {
    "id": "84ca187e-d3a5-4250-88c5-469e662bff78",
    "outputId": "bd13fd30-702b-4cbc-9589-830cb0bc1cc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: matplotlib in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (3.9.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (1.3.0)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (4.55.3)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (1.4.7)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (1.23.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (24.2)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (11.0.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (3.2.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from matplotlib) (6.5.2)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from importlib-resources>=3.2.0->matplotlib) (3.21.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b904ee8f-194e-4c38-9ed7-649e5539ec34",
   "metadata": {
    "id": "b904ee8f-194e-4c38-9ed7-649e5539ec34",
    "outputId": "3b9f1f4c-3e9c-41e9-f879-e95c264d8585"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy>=1.22.4 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas) (1.23.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from pandas) (2024.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8fd18bf0-7f33-44b5-90c1-c113ae337652",
   "metadata": {
    "id": "8fd18bf0-7f33-44b5-90c1-c113ae337652",
    "outputId": "a66edff5-49b6-48c4-86aa-e750f3a2251c",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboardX in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboardX) (1.23.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboardX) (24.2)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboardX) (4.25.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8dca0602-f1e6-4e3f-ae56-033e4f882728",
   "metadata": {
    "id": "8dca0602-f1e6-4e3f-ae56-033e4f882728",
    "outputId": "5d18c88f-3b3d-4eb4-f9ac-e2b9b5f54670"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchsummary in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (1.5.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchsummary\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "QRhG6K3SdAYv",
   "metadata": {
    "id": "QRhG6K3SdAYv"
   },
   "source": [
    "# Adjusting to directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5f70a5c7-5ec8-405a-9c72-2b0e4f4f17c2",
   "metadata": {
    "id": "5f70a5c7-5ec8-405a-9c72-2b0e4f4f17c2",
    "outputId": "c7664303-c670-4135-d9ef-4b63d4e81e2c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current working directory: C:\\Users\\l_alm\\resnet1d-master\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(r'C:\\Users\\l_alm\\resnet1d-master')  #adjust this to your base directory if needed\n",
    "print(f\"Current working directory: {os.getcwd()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "411444ef-51f5-4cfd-929d-88d2f5e902fc",
   "metadata": {
    "id": "411444ef-51f5-4cfd-929d-88d2f5e902fc",
    "outputId": "654f63d5-25a0-46b6-f308-54209452ccc8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torch in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (2.5.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (0.20.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torchvision) (1.23.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from torchvision) (11.0.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from jinja2->torch) (2.1.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade torch torchvision\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f61bdc73-0704-4932-b662-62a293f7ad43",
   "metadata": {
    "id": "f61bdc73-0704-4932-b662-62a293f7ad43",
    "outputId": "7354311e-c02b-4de3-df3a-5a9e9f589dac"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: keras in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (2.12.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install keras\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24da069c-00bc-4b60-ae1e-788d0c6bb5d7",
   "metadata": {
    "id": "24da069c-00bc-4b60-ae1e-788d0c6bb5d7",
    "outputId": "662e16aa-4932-4982-9521-03e6e9f138fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorflow in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (2.12.0)\n",
      "Requirement already satisfied: tensorflow-intel==2.12.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow) (2.12.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=2.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (24.12.23)\n",
      "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=2.9.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.12.1)\n",
      "Requirement already satisfied: jax>=0.3.15 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.4.30)\n",
      "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (18.1.1)\n",
      "Requirement already satisfied: numpy<1.24,>=1.22 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.23.5)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (24.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.25.5)\n",
      "Requirement already satisfied: setuptools in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (75.1.0)\n",
      "Requirement already satisfied: six>=1.12.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.17.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt<1.15,>=1.11.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (1.69.0)\n",
      "Requirement already satisfied: tensorboard<2.13,>=2.12 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.3)\n",
      "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: keras<2.13,>=2.12.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (2.12.0)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorflow-intel==2.12.0->tensorflow) (0.31.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from astunparse>=1.6.0->tensorflow-intel==2.12.0->tensorflow) (0.44.0)\n",
      "Requirement already satisfied: jaxlib<=0.4.30,>=0.4.27 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.4.30)\n",
      "Requirement already satisfied: ml-dtypes>=0.2.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: scipy>=1.9 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (1.13.1)\n",
      "Requirement already satisfied: importlib-metadata>=4.6 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (8.5.0)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.37.0)\n",
      "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (1.0.0)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.32.3)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.1.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (5.5.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.4.1)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (4.9)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.0.0)\n",
      "Requirement already satisfied: zipp>=3.20 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from importlib-metadata>=4.6->jax>=0.3.15->tensorflow-intel==2.12.0->tensorflow) (3.21.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.2.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2024.12.14)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.4.6 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow-intel==2.12.0->tensorflow) (3.2.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "503a27db-97b0-49d5-917e-a7cc6d9847f0",
   "metadata": {
    "id": "503a27db-97b0-49d5-917e-a7cc6d9847f0",
    "outputId": "d3f4f23d-644f-4217-c639-aee3a66fc33f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully imported pad_sequences from TensorFlow Keras\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "print(\"Successfully imported pad_sequences from TensorFlow Keras\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "UtdqZhtVdcoS",
   "metadata": {
    "id": "UtdqZhtVdcoS"
   },
   "source": [
    "# checkng if there is enough memory for training\n",
    "\n",
    "> Add blockquote\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "eba9e127-5541-4791-8488-0a6eae305f3b",
   "metadata": {
    "id": "eba9e127-5541-4791-8488-0a6eae305f3b",
    "outputId": "a3692b23-cef8-4789-f2e4-ecce11cb9036"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available memory: 2.22 GB\n",
      "Total memory: 16.94 GB\n"
     ]
    }
   ],
   "source": [
    "import psutil\n",
    "\n",
    "memory = psutil.virtual_memory()\n",
    "print(f\"Available memory: {memory.available / 1e9:.2f} GB\")\n",
    "print(f\"Total memory: {memory.total / 1e9:.2f} GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "2da8bf55-1aa5-4323-921b-4c758fa453cd",
   "metadata": {
    "id": "2da8bf55-1aa5-4323-921b-4c758fa453cd"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def read_data_generated(n_samples, n_length, n_channel, n_classes, verbose=False):\n",
    "    \"\"\"\n",
    "    Generated data\n",
    "\n",
    "    This generated data contains one noise channel class, plus unlimited number of sine channel classes which are different on frequency.\n",
    "\n",
    "    \"\"\"\n",
    "    all_X = []\n",
    "    all_Y = []\n",
    "\n",
    "    # noise channel class\n",
    "    X_noise = np.random.rand(n_samples, n_channel, n_length)\n",
    "    Y_noise = np.array([0]*n_samples)\n",
    "    all_X.append(X_noise)\n",
    "    all_Y.append(Y_noise)\n",
    "\n",
    "    # sine channel classe\n",
    "    x = np.arange(n_length)\n",
    "    for i_class in range(n_classes-1):\n",
    "        scale = 2**i_class\n",
    "        offset_list = 2*np.pi*np.random.rand(n_samples)\n",
    "        X_sin = []\n",
    "        for i_sample in range(n_samples):\n",
    "            tmp_x = []\n",
    "            for i_channel in range(n_channel):\n",
    "                tmp_x.append(np.sin(x/scale+2*np.pi*np.random.rand()))\n",
    "            X_sin.append(tmp_x)\n",
    "        X_sin = np.array(X_sin)\n",
    "        Y_sin = np.array([i_class+1]*n_samples)\n",
    "        all_X.append(X_sin)\n",
    "        all_Y.append(Y_sin)\n",
    "\n",
    "    # combine and shuffle\n",
    "    all_X = np.concatenate(all_X)\n",
    "    all_Y = np.concatenate(all_Y)\n",
    "    shuffle_idx = np.random.permutation(all_Y.shape[0])\n",
    "    all_X = all_X[shuffle_idx]\n",
    "    all_Y = all_Y[shuffle_idx]\n",
    "\n",
    "    # random pick some and plot\n",
    "    if verbose:\n",
    "        for _ in np.random.permutation(all_Y.shape[0])[:10]:\n",
    "            fig = plt.figure()\n",
    "            plt.plot(all_X[_,0,:])\n",
    "            plt.title('Label: {0}'.format(all_Y[_]))\n",
    "\n",
    "    return all_X, all_Y\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "  #  read_data_physionet_2_clean_federated(m_clients=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "K1rl1xPfd2k1",
   "metadata": {
    "id": "K1rl1xPfd2k1"
   },
   "source": [
    "# 1d resnet model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "66139199-e043-42d1-9b1f-4c612df9656a",
   "metadata": {
    "id": "66139199-e043-42d1-9b1f-4c612df9656a"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "resnet for 1-d signal data, pytorch version\n",
    "\n",
    "Shenda Hong, Oct 2019\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (torch.tensor(self.data[index], dtype=torch.float), torch.tensor(self.label[index], dtype=torch.long))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class MyConv1dPadSame(nn.Module):\n",
    "    \"\"\"\n",
    "    extend nn.Conv1d to support SAME padding\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups=1):\n",
    "        super(MyConv1dPadSame, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.conv = torch.nn.Conv1d(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            groups=self.groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        net = x\n",
    "\n",
    "        # compute pad shape\n",
    "        in_dim = net.shape[-1]\n",
    "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
    "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
    "        pad_left = p // 2\n",
    "        pad_right = p - pad_left\n",
    "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
    "\n",
    "        net = self.conv(net)\n",
    "\n",
    "        return net\n",
    "\n",
    "class MyMaxPool1dPadSame(nn.Module):\n",
    "    \"\"\"\n",
    "    extend nn.MaxPool1d to support SAME padding\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(MyMaxPool1dPadSame, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = 1\n",
    "        self.max_pool = torch.nn.MaxPool1d(kernel_size=self.kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        net = x\n",
    "\n",
    "        # compute pad shape\n",
    "        in_dim = net.shape[-1]\n",
    "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
    "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
    "        pad_left = p // 2\n",
    "        pad_right = p - pad_left\n",
    "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
    "\n",
    "        net = self.max_pool(net)\n",
    "\n",
    "        return net\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet Basic Block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups, downsample, use_bn, use_do, is_first_block=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.downsample = downsample\n",
    "        if self.downsample:\n",
    "            self.stride = stride\n",
    "        else:\n",
    "            self.stride = 1\n",
    "        self.is_first_block = is_first_block\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "\n",
    "        # the first conv\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.do1 = nn.Dropout(p=0.5)\n",
    "        self.conv1 = MyConv1dPadSame(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=self.stride,\n",
    "            groups=self.groups)\n",
    "\n",
    "        # the second conv\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.do2 = nn.Dropout(p=0.5)\n",
    "        self.conv2 = MyConv1dPadSame(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            groups=self.groups)\n",
    "\n",
    "        self.max_pool = MyMaxPool1dPadSame(kernel_size=self.stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x\n",
    "\n",
    "        # the first conv\n",
    "        out = x\n",
    "        if not self.is_first_block:\n",
    "            if self.use_bn:\n",
    "                out = self.bn1(out)\n",
    "            out = self.relu1(out)\n",
    "            if self.use_do:\n",
    "                out = self.do1(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        # the second conv\n",
    "        if self.use_bn:\n",
    "            out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        if self.use_do:\n",
    "            out = self.do2(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        # if downsample, also downsample identity\n",
    "        if self.downsample:\n",
    "            identity = self.max_pool(identity)\n",
    "\n",
    "        # if expand channel, also pad zeros to identity\n",
    "        if self.out_channels != self.in_channels:\n",
    "            identity = identity.transpose(-1,-2)\n",
    "            ch1 = (self.out_channels-self.in_channels)//2\n",
    "            ch2 = self.out_channels-self.in_channels-ch1\n",
    "            identity = F.pad(identity, (ch1, ch2), \"constant\", 0)\n",
    "            identity = identity.transpose(-1,-2)\n",
    "\n",
    "        # shortcut\n",
    "        out += identity\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet1D(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    Input:\n",
    "        X: (n_samples, n_channel, n_length)\n",
    "        Y: (n_samples)\n",
    "\n",
    "    Output:\n",
    "        out: (n_samples)\n",
    "\n",
    "    Pararmetes:\n",
    "        in_channels: dim of input, the same as n_channel\n",
    "        base_filters: number of filters in the first several Conv layer, it will double at every 4 layers\n",
    "        kernel_size: width of kernel\n",
    "        stride: stride of kernel moving\n",
    "        groups: set larget to 1 as ResNeXt\n",
    "        n_block: number of blocks\n",
    "        n_classes: number of classes\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, base_filters, kernel_size, stride, groups, n_block, n_classes, downsample_gap=2, increasefilter_gap=4, use_bn=True, use_do=True, verbose=False):\n",
    "        super(ResNet1D, self).__init__()\n",
    "\n",
    "        self.verbose = verbose\n",
    "        self.n_block = n_block\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "\n",
    "        self.downsample_gap = downsample_gap # 2 for base model\n",
    "        self.increasefilter_gap = increasefilter_gap # 4 for base model\n",
    "\n",
    "        # first block\n",
    "        self.first_block_conv = MyConv1dPadSame(in_channels=in_channels, out_channels=base_filters, kernel_size=self.kernel_size, stride=1)\n",
    "        self.first_block_bn = nn.BatchNorm1d(base_filters)\n",
    "        self.first_block_relu = nn.ReLU()\n",
    "        out_channels = base_filters\n",
    "\n",
    "        # residual blocks\n",
    "        self.basicblock_list = nn.ModuleList()\n",
    "        for i_block in range(self.n_block):\n",
    "            # is_first_block\n",
    "            if i_block == 0:\n",
    "                is_first_block = True\n",
    "            else:\n",
    "                is_first_block = False\n",
    "            # downsample at every self.downsample_gap blocks\n",
    "            if i_block % self.downsample_gap == 1:\n",
    "                downsample = True\n",
    "            else:\n",
    "                downsample = False\n",
    "            # in_channels and out_channels\n",
    "            if is_first_block:\n",
    "                in_channels = base_filters\n",
    "                out_channels = in_channels\n",
    "            else:\n",
    "                # increase filters at every self.increasefilter_gap blocks\n",
    "                in_channels = int(base_filters*2**((i_block-1)//self.increasefilter_gap))\n",
    "                if (i_block % self.increasefilter_gap == 0) and (i_block != 0):\n",
    "                    out_channels = in_channels * 2\n",
    "                else:\n",
    "                    out_channels = in_channels\n",
    "\n",
    "            tmp_block = BasicBlock(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=self.kernel_size,\n",
    "                stride = self.stride,\n",
    "                groups = self.groups,\n",
    "                downsample=downsample,\n",
    "                use_bn = self.use_bn,\n",
    "                use_do = self.use_do,\n",
    "                is_first_block=is_first_block)\n",
    "            self.basicblock_list.append(tmp_block)\n",
    "\n",
    "        # final prediction\n",
    "        self.final_bn = nn.BatchNorm1d(out_channels)\n",
    "        self.final_relu = nn.ReLU(inplace=True)\n",
    "        # self.do = nn.Dropout(p=0.5)\n",
    "        self.dense = nn.Linear(out_channels, n_classes)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = x\n",
    "\n",
    "        # first conv\n",
    "        if self.verbose:\n",
    "            print('input shape', out.shape)\n",
    "        out = self.first_block_conv(out)\n",
    "        if self.verbose:\n",
    "            print('after first conv', out.shape)\n",
    "        if self.use_bn:\n",
    "            out = self.first_block_bn(out)\n",
    "        out = self.first_block_relu(out)\n",
    "\n",
    "        # residual blocks, every block has two conv\n",
    "        for i_block in range(self.n_block):\n",
    "            net = self.basicblock_list[i_block]\n",
    "            if self.verbose:\n",
    "                print('i_block: {0}, in_channels: {1}, out_channels: {2}, downsample: {3}'.format(i_block, net.in_channels, net.out_channels, net.downsample))\n",
    "            out = net(out)\n",
    "            if self.verbose:\n",
    "                print(out.shape)\n",
    "\n",
    "        # final prediction\n",
    "        if self.use_bn:\n",
    "            out = self.final_bn(out)\n",
    "        out = self.final_relu(out)\n",
    "        out = out.mean(-1)\n",
    "        if self.verbose:\n",
    "            print('final pooling', out.shape)\n",
    "        # out = self.do(out)\n",
    "        out = self.dense(out)\n",
    "        if self.verbose:\n",
    "            print('dense', out.shape)\n",
    "        # out = self.softmax(out)\n",
    "        if self.verbose:\n",
    "            print('softmax', out.shape)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "80fe173f-caa7-42d5-bcc6-ea2e8d3c1343",
   "metadata": {
    "id": "80fe173f-caa7-42d5-bcc6-ea2e8d3c1343"
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "resnet for 1-d signal data, pytorch version\n",
    "\n",
    "Shenda Hong, Oct 2019\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, data, label):\n",
    "        self.data = data\n",
    "        self.label = label\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        return (torch.tensor(self.data[index], dtype=torch.float), torch.tensor(self.label[index], dtype=torch.long))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "class MyConv1dPadSame(nn.Module):\n",
    "    \"\"\"\n",
    "    extend nn.Conv1d to support SAME padding\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups=1):\n",
    "        super(MyConv1dPadSame, self).__init__()\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.conv = torch.nn.Conv1d(\n",
    "            in_channels=self.in_channels,\n",
    "            out_channels=self.out_channels,\n",
    "            kernel_size=self.kernel_size,\n",
    "            stride=self.stride,\n",
    "            groups=self.groups)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        net = x\n",
    "\n",
    "        # compute pad shape\n",
    "        in_dim = net.shape[-1]\n",
    "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
    "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
    "        pad_left = p // 2\n",
    "        pad_right = p - pad_left\n",
    "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
    "\n",
    "        net = self.conv(net)\n",
    "\n",
    "        return net\n",
    "\n",
    "class MyMaxPool1dPadSame(nn.Module):\n",
    "    \"\"\"\n",
    "    extend nn.MaxPool1d to support SAME padding\n",
    "    \"\"\"\n",
    "    def __init__(self, kernel_size):\n",
    "        super(MyMaxPool1dPadSame, self).__init__()\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = 1\n",
    "        self.max_pool = torch.nn.MaxPool1d(kernel_size=self.kernel_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        net = x\n",
    "\n",
    "        # compute pad shape\n",
    "        in_dim = net.shape[-1]\n",
    "        out_dim = (in_dim + self.stride - 1) // self.stride\n",
    "        p = max(0, (out_dim - 1) * self.stride + self.kernel_size - in_dim)\n",
    "        pad_left = p // 2\n",
    "        pad_right = p - pad_left\n",
    "        net = F.pad(net, (pad_left, pad_right), \"constant\", 0)\n",
    "\n",
    "        net = self.max_pool(net)\n",
    "\n",
    "        return net\n",
    "\n",
    "class BasicBlock(nn.Module):\n",
    "    \"\"\"\n",
    "    ResNet Basic Block\n",
    "    \"\"\"\n",
    "    def __init__(self, in_channels, out_channels, kernel_size, stride, groups, downsample, use_bn, use_do, is_first_block=False):\n",
    "        super(BasicBlock, self).__init__()\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.kernel_size = kernel_size\n",
    "        self.out_channels = out_channels\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.downsample = downsample\n",
    "        if self.downsample:\n",
    "            self.stride = stride\n",
    "        else:\n",
    "            self.stride = 1\n",
    "        self.is_first_block = is_first_block\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "\n",
    "        # the first conv\n",
    "        self.bn1 = nn.BatchNorm1d(in_channels)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.do1 = nn.Dropout(p=0.5)\n",
    "        self.conv1 = MyConv1dPadSame(\n",
    "            in_channels=in_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=self.stride,\n",
    "            groups=self.groups)\n",
    "\n",
    "        # the second conv\n",
    "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.do2 = nn.Dropout(p=0.5)\n",
    "        self.conv2 = MyConv1dPadSame(\n",
    "            in_channels=out_channels,\n",
    "            out_channels=out_channels,\n",
    "            kernel_size=kernel_size,\n",
    "            stride=1,\n",
    "            groups=self.groups)\n",
    "\n",
    "        self.max_pool = MyMaxPool1dPadSame(kernel_size=self.stride)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        identity = x\n",
    "\n",
    "        # the first conv\n",
    "        out = x\n",
    "        if not self.is_first_block:\n",
    "            if self.use_bn:\n",
    "                out = self.bn1(out)\n",
    "            out = self.relu1(out)\n",
    "            if self.use_do:\n",
    "                out = self.do1(out)\n",
    "        out = self.conv1(out)\n",
    "\n",
    "        # the second conv\n",
    "        if self.use_bn:\n",
    "            out = self.bn2(out)\n",
    "        out = self.relu2(out)\n",
    "        if self.use_do:\n",
    "            out = self.do2(out)\n",
    "        out = self.conv2(out)\n",
    "\n",
    "        # if downsample, also downsample identity\n",
    "        if self.downsample:\n",
    "            identity = self.max_pool(identity)\n",
    "\n",
    "        # if expand channel, also pad zeros to identity\n",
    "        if self.out_channels != self.in_channels:\n",
    "            identity = identity.transpose(-1,-2)\n",
    "            ch1 = (self.out_channels-self.in_channels)//2\n",
    "            ch2 = self.out_channels-self.in_channels-ch1\n",
    "            identity = F.pad(identity, (ch1, ch2), \"constant\", 0)\n",
    "            identity = identity.transpose(-1,-2)\n",
    "\n",
    "        # shortcut\n",
    "        out += identity\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet1D(nn.Module):\n",
    "    \"\"\"\n",
    "\n",
    "    Input:\n",
    "        X: (n_samples, n_channel, n_length)\n",
    "        Y: (n_samples)\n",
    "\n",
    "    Output:\n",
    "        out: (n_samples)\n",
    "\n",
    "    Pararmetes:\n",
    "        in_channels: dim of input, the same as n_channel\n",
    "        base_filters: number of filters in the first several Conv layer, it will double at every 4 layers\n",
    "        kernel_size: width of kernel\n",
    "        stride: stride of kernel moving\n",
    "        groups: set larget to 1 as ResNeXt\n",
    "        n_block: number of blocks\n",
    "        n_classes: number of classes\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels, base_filters, kernel_size, stride, groups, n_block, n_classes, downsample_gap=2, increasefilter_gap=4, use_bn=True, use_do=True, verbose=False):\n",
    "        super(ResNet1D, self).__init__()\n",
    "\n",
    "        self.verbose = verbose\n",
    "        self.n_block = n_block\n",
    "        self.kernel_size = kernel_size\n",
    "        self.stride = stride\n",
    "        self.groups = groups\n",
    "        self.use_bn = use_bn\n",
    "        self.use_do = use_do\n",
    "\n",
    "        self.downsample_gap = downsample_gap # 2 for base model\n",
    "        self.increasefilter_gap = increasefilter_gap # 4 for base model\n",
    "\n",
    "        # first block\n",
    "        self.first_block_conv = MyConv1dPadSame(in_channels=in_channels, out_channels=base_filters, kernel_size=self.kernel_size, stride=1)\n",
    "        self.first_block_bn = nn.BatchNorm1d(base_filters)\n",
    "        self.first_block_relu = nn.ReLU()\n",
    "        out_channels = base_filters\n",
    "\n",
    "        # residual blocks\n",
    "        self.basicblock_list = nn.ModuleList()\n",
    "        for i_block in range(self.n_block):\n",
    "            # is_first_block\n",
    "            if i_block == 0:\n",
    "                is_first_block = True\n",
    "            else:\n",
    "                is_first_block = False\n",
    "            # downsample at every self.downsample_gap blocks\n",
    "            if i_block % self.downsample_gap == 1:\n",
    "                downsample = True\n",
    "            else:\n",
    "                downsample = False\n",
    "            # in_channels and out_channels\n",
    "            if is_first_block:\n",
    "                in_channels = base_filters\n",
    "                out_channels = in_channels\n",
    "            else:\n",
    "                # increase filters at every self.increasefilter_gap blocks\n",
    "                in_channels = int(base_filters*2**((i_block-1)//self.increasefilter_gap))\n",
    "                if (i_block % self.increasefilter_gap == 0) and (i_block != 0):\n",
    "                    out_channels = in_channels * 2\n",
    "                else:\n",
    "                    out_channels = in_channels\n",
    "\n",
    "            tmp_block = BasicBlock(\n",
    "                in_channels=in_channels,\n",
    "                out_channels=out_channels,\n",
    "                kernel_size=self.kernel_size,\n",
    "                stride = self.stride,\n",
    "                groups = self.groups,\n",
    "                downsample=downsample,\n",
    "                use_bn = self.use_bn,\n",
    "                use_do = self.use_do,\n",
    "                is_first_block=is_first_block)\n",
    "            self.basicblock_list.append(tmp_block)\n",
    "\n",
    "        # final prediction\n",
    "        self.final_bn = nn.BatchNorm1d(out_channels)\n",
    "        self.final_relu = nn.ReLU(inplace=True)\n",
    "        # self.do = nn.Dropout(p=0.5)\n",
    "        self.dense = nn.Linear(out_channels, n_classes)\n",
    "        # self.softmax = nn.Softmax(dim=1)\n",
    "\n",
    "    def forward(self, x):\n",
    "\n",
    "        out = x\n",
    "\n",
    "        # first conv\n",
    "        if self.verbose:\n",
    "            print('input shape', out.shape)\n",
    "        out = self.first_block_conv(out)\n",
    "        if self.verbose:\n",
    "            print('after first conv', out.shape)\n",
    "        if self.use_bn:\n",
    "            out = self.first_block_bn(out)\n",
    "        out = self.first_block_relu(out)\n",
    "\n",
    "        # residual blocks, every block has two conv\n",
    "        for i_block in range(self.n_block):\n",
    "            net = self.basicblock_list[i_block]\n",
    "            if self.verbose:\n",
    "                print('i_block: {0}, in_channels: {1}, out_channels: {2}, downsample: {3}'.format(i_block, net.in_channels, net.out_channels, net.downsample))\n",
    "            out = net(out)\n",
    "            if self.verbose:\n",
    "                print(out.shape)\n",
    "\n",
    "        # final prediction\n",
    "        if self.use_bn:\n",
    "            out = self.final_bn(out)\n",
    "        out = self.final_relu(out)\n",
    "        out = out.mean(-1)\n",
    "        if self.verbose:\n",
    "            print('final pooling', out.shape)\n",
    "        # out = self.do(out)\n",
    "        out = self.dense(out)\n",
    "        if self.verbose:\n",
    "            print('dense', out.shape)\n",
    "        # out = self.softmax(out)\n",
    "        if self.verbose:\n",
    "            print('softmax', out.shape)\n",
    "\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "74f7f7a6-3fe1-4679-b7c3-c77ae9f64ed5",
   "metadata": {
    "id": "74f7f7a6-3fe1-4679-b7c3-c77ae9f64ed5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from collections import Counter\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def read_data_generated(n_samples, n_length, n_channel, n_classes, verbose=False):\n",
    "    \"\"\"\n",
    "    Generated data\n",
    "\n",
    "    This generated data contains one noise channel class, plus unlimited number of sine channel classes which are different on frequency.\n",
    "\n",
    "    \"\"\"\n",
    "    all_X = []\n",
    "    all_Y = []\n",
    "\n",
    "    # noise channel class\n",
    "    X_noise = np.random.rand(n_samples, n_channel, n_length)\n",
    "    Y_noise = np.array([0]*n_samples)\n",
    "    all_X.append(X_noise)\n",
    "    all_Y.append(Y_noise)\n",
    "\n",
    "    # sine channel classe\n",
    "    x = np.arange(n_length)\n",
    "    for i_class in range(n_classes-1):\n",
    "        scale = 2**i_class\n",
    "        offset_list = 2*np.pi*np.random.rand(n_samples)\n",
    "        X_sin = []\n",
    "        for i_sample in range(n_samples):\n",
    "            tmp_x = []\n",
    "            for i_channel in range(n_channel):\n",
    "                tmp_x.append(np.sin(x/scale+2*np.pi*np.random.rand()))\n",
    "            X_sin.append(tmp_x)\n",
    "        X_sin = np.array(X_sin)\n",
    "        Y_sin = np.array([i_class+1]*n_samples)\n",
    "        all_X.append(X_sin)\n",
    "        all_Y.append(Y_sin)\n",
    "\n",
    "    # combine and shuffle\n",
    "    all_X = np.concatenate(all_X)\n",
    "    all_Y = np.concatenate(all_Y)\n",
    "    shuffle_idx = np.random.permutation(all_Y.shape[0])\n",
    "    all_X = all_X[shuffle_idx]\n",
    "    all_Y = all_Y[shuffle_idx]\n",
    "\n",
    "    # random pick some and plot\n",
    "    if verbose:\n",
    "        for _ in np.random.permutation(all_Y.shape[0])[:10]:\n",
    "            fig = plt.figure()\n",
    "            plt.plot(all_X[_,0,:])\n",
    "            plt.title('Label: {0}'.format(all_Y[_]))\n",
    "\n",
    "    return all_X, all_Y\n",
    "\n",
    "\n",
    "#if __name__ == \"__main__\":\n",
    "  #  read_data_physionet_2_clean_federated(m_clients=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "994b7f0e-e887-425f-b52a-6e9a71ef10c9",
   "metadata": {
    "id": "994b7f0e-e887-425f-b52a-6e9a71ef10c9",
    "outputId": "c239a1f3-f1ad-44c8-efa7-f2e377c247d4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tensorboardX in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (2.6.2.2)\n",
      "Requirement already satisfied: numpy in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboardX) (1.23.5)\n",
      "Requirement already satisfied: packaging in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboardX) (24.2)\n",
      "Requirement already satisfied: protobuf>=3.20 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from tensorboardX) (4.25.5)\n"
     ]
    }
   ],
   "source": [
    "!pip install tensorboardX"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nJikrHgWeIMu",
   "metadata": {
    "id": "nJikrHgWeIMu"
   },
   "source": [
    "# Preprocessing function has scaling and encoding.."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03b95b64-46c6-42a5-aced-17c6ca3843af",
   "metadata": {
    "id": "03b95b64-46c6-42a5-aced-17c6ca3843af"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import torch\n",
    "def preprocess_data(file_path):\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Handle missing values (drop rows with missing data)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Encode categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    # Separate features and labels\n",
    "    X = df.drop(\"target\", axis=1)\n",
    "    y = df[\"target\"]\n",
    "\n",
    "    # Normalize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Split into train and test sets\n",
    "    n_samples , n_features = X.shape\n",
    "    n_channel = n_features\n",
    "    n_length = 1\n",
    "\n",
    "    X = X.reshape(n_samples, n_channel, n_length)\n",
    "\n",
    "\n",
    "\n",
    "    return X ,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "de1YLdQeiOWm",
   "metadata": {
    "id": "de1YLdQeiOWm"
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "def preprocess_data_with_smote(file_path):\n",
    "    \"\"\"\n",
    "    Preprocess the input CSV data for ResNet1D with SMOTE.\n",
    "\n",
    "    Args:\n",
    "        file_path (str): Path to the CSV file.\n",
    "\n",
    "    Returns:\n",
    "        tuple: Processed data (X), labels (y).\n",
    "    \"\"\"\n",
    "    # Load dataset\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # Handle missing values (drop rows with missing data)\n",
    "    df = df.dropna()\n",
    "\n",
    "    # Encode categorical columns\n",
    "    categorical_cols = df.select_dtypes(include=['object']).columns\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df[col] = le.fit_transform(df[col])\n",
    "        label_encoders[col] = le\n",
    "\n",
    "    # Separate features and labels\n",
    "    X = df.drop(\"target\", axis=1).values\n",
    "    y = df[\"target\"].values\n",
    "\n",
    "    # Normalize numerical features\n",
    "    scaler = StandardScaler()\n",
    "    X = scaler.fit_transform(X)\n",
    "\n",
    "    # Apply SMOTE to balance the classes\n",
    "    smote = SMOTE(random_state=42)\n",
    "    X, y = smote.fit_resample(X, y)\n",
    "\n",
    "    # Reshape data for ResNet1D\n",
    "    n_samples, n_features = X.shape\n",
    "    n_channel = n_features\n",
    "    n_length = 1\n",
    "\n",
    "    X = X.reshape(n_samples, n_channel, n_length)\n",
    "\n",
    "    return X, y\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9e927808-41fd-48b1-b552-e3a7aa60d00b",
   "metadata": {
    "id": "9e927808-41fd-48b1-b552-e3a7aa60d00b",
    "outputId": "2c95209c-2cf5-4ad2-cddf-03628242d286"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: imbalanced-learn in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (0.12.4)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from imbalanced-learn) (1.23.5)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from imbalanced-learn) (1.13.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from imbalanced-learn) (1.5.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from imbalanced-learn) (1.4.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages (from imbalanced-learn) (3.5.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install imbalanced-learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "JyusqUmueZL9",
   "metadata": {
    "id": "JyusqUmueZL9"
   },
   "source": [
    "# Model Training and evaluating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ad12eba8-a11f-4602-96fc-e6f290acffc6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "ad12eba8-a11f-4602-96fc-e6f290acffc6",
    "outputId": "0618c421-e9e7-4868-ad11-6780ee349b16"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"C:\\Users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\subprocess.py\", line 505, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"C:\\Users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\subprocess.py\", line 951, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\l_alm\\miniconda3\\envs\\pytorch_env\\lib\\subprocess.py\", line 1436, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9228, 70, 1) Counter({2: 3076, 1: 3076, 0: 3076})\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Sum of input lengths does not equal the length of the input dataset!",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m dataset \u001b[38;5;241m=\u001b[39m MyDataset(data, label)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Split dataset and prepare DataLoaders\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m train_set, val_set \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mutils\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrandom_split\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m5000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1620\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     19\u001b[0m train_loader \u001b[38;5;241m=\u001b[39m DataLoader(train_set, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     20\u001b[0m test_loader \u001b[38;5;241m=\u001b[39m DataLoader(val_set, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m64\u001b[39m, shuffle\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32m~\\miniconda3\\envs\\pytorch_env\\lib\\site-packages\\torch\\utils\\data\\dataset.py:480\u001b[0m, in \u001b[0;36mrandom_split\u001b[1;34m(dataset, lengths, generator)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[38;5;66;03m# Cannot verify that dataset is Sized\u001b[39;00m\n\u001b[0;32m    479\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28msum\u001b[39m(lengths) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(dataset):  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m--> 480\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    481\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSum of input lengths does not equal the length of the input dataset!\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    482\u001b[0m     )\n\u001b[0;32m    484\u001b[0m indices \u001b[38;5;241m=\u001b[39m randperm(\u001b[38;5;28msum\u001b[39m(lengths), generator\u001b[38;5;241m=\u001b[39mgenerator)\u001b[38;5;241m.\u001b[39mtolist()  \u001b[38;5;66;03m# type: ignore[arg-type, call-overload]\u001b[39;00m\n\u001b[0;32m    485\u001b[0m lengths \u001b[38;5;241m=\u001b[39m cast(Sequence[\u001b[38;5;28mint\u001b[39m], lengths)\n",
      "\u001b[1;31mValueError\u001b[0m: Sum of input lengths does not equal the length of the input dataset!"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.metrics import f1_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import tqdm\n",
    "from imblearn.over_sampling import SMOTE\n",
    "# Assuming the preprocess_data, MyDataset, and ResNet1D definitions are correct and loaded above this code\n",
    "\n",
    "# Load and preprocess data\n",
    "#data, label = preprocess_data(r'C:\\Users\\l_alm\\resnet1d-master\\content\\customerTargeting.csv')\n",
    "data, label = preprocess_data_with_smote(r'C:\\Users\\l_alm\\resnet1d-master\\content\\customerTargeting.csv')\n",
    "print(data.shape, Counter(label))\n",
    "dataset = MyDataset(data, label)\n",
    "\n",
    "# Split dataset and prepare DataLoaders\n",
    "train_set, val_set = torch.utils.data.random_split(dataset, [5000, 1620])\n",
    "train_loader = DataLoader(train_set, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(val_set, batch_size=64, shuffle=True)\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "n_classes = 3\n",
    "\n",
    "model = ResNet1D(\n",
    "    in_channels=70, #NO of features\n",
    "    base_filters=64,#on the authors github repository he added a comment that 64 is for resnet1d\n",
    "    kernel_size=1, #each feature processed independently\n",
    "    stride=1,\n",
    "    n_block=8,#to align with ResNet18\n",
    "    groups=1,\n",
    "    n_classes=n_classes,\n",
    "    downsample_gap=1,#downsampling happens at every block ->  increases the efficiency of feature compression\n",
    "    increasefilter_gap=8,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "\n",
    "\n",
    "model.to(device)\n",
    "\n",
    "# Optimizer, loss function, and scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-5, weight_decay=1e-4)  # Lower learning rate\n",
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.1, patience=10)\n",
    "class_weights = compute_class_weight('balanced', classes=np.unique(label), y=label)\n",
    "class_weights = torch.tensor(class_weights, dtype=torch.float).to(device)\n",
    "\n",
    "loss_func = torch.nn.CrossEntropyLoss(weight=class_weights)\n",
    "\n",
    "#early stopping parameters\n",
    "early_stopping_patience = 20\n",
    "best_val_loss = float('inf')\n",
    "patience_counter = 0\n",
    "\n",
    "#training settings\n",
    "n_epoch = 200\n",
    "\n",
    "# Training and validation loop\n",
    "for epoch in range(n_epoch):\n",
    "    # Training\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    all_train_labels = []\n",
    "    all_train_preds = []\n",
    "\n",
    "    for batch in tqdm(train_loader, desc=f\"Training Epoch {epoch+1}\", leave=False):\n",
    "        input_x, input_y = tuple(t.to(device) for t in batch)\n",
    "        pred = model(input_x)\n",
    "        loss = loss_func(pred, input_y)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        all_train_labels.extend(input_y.cpu().numpy())\n",
    "        all_train_preds.extend(pred.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "    # Compute training F1 score\n",
    "    train_f1 = f1_score(all_train_labels, all_train_preds, average='weighted')\n",
    "    print(f\"Epoch {epoch+1}: Train Loss = {train_loss:.4f}, Train F1 = {train_f1:.4f}\")\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    all_val_labels = []\n",
    "    all_val_preds = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(test_loader, desc=f\"Validation Epoch {epoch+1}\", leave=False):\n",
    "            input_x, input_y = tuple(t.to(device) for t in batch)\n",
    "            pred = model(input_x)\n",
    "            loss = loss_func(pred, input_y)\n",
    "            val_loss += loss.item()\n",
    "            all_val_labels.extend(input_y.cpu().numpy())\n",
    "            all_val_preds.extend(pred.argmax(dim=1).cpu().numpy())\n",
    "\n",
    "    # Compute validation F1 score\n",
    "    val_f1 = f1_score(all_val_labels, all_val_preds, average='weighted')\n",
    "    print(f\"Epoch {epoch+1}: Val Loss = {val_loss:.4f}, Val F1 = {val_f1:.4f}\")\n",
    "    scheduler.step(val_loss)\n",
    "\n",
    "    # Early stopping logic\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        patience_counter = 0\n",
    "        torch.save(model.state_dict(), \"best_model.pth\")  # Save the best model\n",
    "    else:\n",
    "        patience_counter += 1\n",
    "\n",
    "    if patience_counter >= early_stopping_patience:\n",
    "        print(\"Early stopping triggered!\")\n",
    "        break\n",
    "\n",
    "\n",
    "\n",
    "# Final evaluation\n",
    "model.load_state_dict(torch.load(\"best_model.pth\"))\n",
    "model.eval()\n",
    "\n",
    "all_pred_prob = []\n",
    "with torch.no_grad():\n",
    "    for batch in tqdm(test_loader, desc=\"Final Testing\", leave=False):\n",
    "        input_x, input_y = tuple(t.to(device) for t in batch)\n",
    "        pred = model(input_x)\n",
    "        all_pred_prob.append(pred.cpu().data.numpy())\n",
    "\n",
    "all_pred_prob = np.concatenate(all_pred_prob)\n",
    "all_pred = np.argmax(all_pred_prob, axis=1)\n",
    "\n",
    "all_test_labels = []\n",
    "for _, labels in test_loader:\n",
    "    all_test_labels.extend(labels.numpy())\n",
    "\n",
    "all_test_labels = np.array(all_test_labels)\n",
    "print(\"Test Labels:\", all_test_labels)\n",
    "print(classification_report(all_pred, all_test_labels))\n",
    "print('Training complete.')\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
